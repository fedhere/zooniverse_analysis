# -*- coding: utf-8 -*-
"""Zooniverse_analysis_FBB_02012026.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F31qiErgAra-4Bdd7sru_KMyb_H-IcMy
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import LogNorm
import seaborn as sns
from tqdm import tqdm
from IPython.display import Image, display, HTML
import json
import os

from zooniverse_config import *

def processclassifications(infile, workflow_id="24125",
                           workflow_creation_date=None, verbose=False,
                           savefile=False):
  chunk_size = 100_000
  chunks = []
  if verbose:
    print(f"reading in file {infile}")
  
  for chunk in tqdm(pd.read_csv(infile, chunksize=chunk_size, low_memory=False)):
    # Process each chunk as needed
    chunks.append(chunk)
    zooniverse = pd.concat(chunks).drop_duplicates()

  if verbose:
    print(f"{zooniverse.workflow_id.unique()}, {zooniverse.workflow_version.unique()}")
    print(f"setting workflow to workflow_id == {workflow_id} and created_at > {workflow_creation_date}")
  if workflow_creation_date is None:
    zooniverse = zooniverse.query(f'workflow_id == {workflow_id}')
  else:
    zooniverse = zooniverse.query(f'workflow_id == {workflow_id} and created_at > {pd.to_datetime(workflow_creation_date)}')

    
  
  # Apply json.loads to each element in the 'annotations' column
  # and convert the resulting Series to a list.
  # The lambda function handles potential non-string values (like NaN) by returning an empty list.
  annotations = zooniverse['annotations'].apply(
      lambda x: json.loads(x) if isinstance(x, str) else []
  )


  nannotations = np.array([len(a) for a in annotations])
  #check for annotation on same subject by same user
  greaterthanoneannotation = nannotations>1
  if verbose:
    print(f"number of multiple annotations by same user on same subject? {(greaterthanoneannotation>0).sum()}")
  zooniverse = zooniverse[~greaterthanoneannotation] #removing where there were more than one annotations

  assert (greaterthanoneannotation>0).sum()==0, "there are annotations by the same user on the same subject"
  
  #set label column
  zooniverse["label"] = [a[0]["value"] for a in annotations]

  
  #save subjects list
  subjects = zooniverse['subject_data'].apply(
    lambda x: json.loads(x) if isinstance(x, str) else []
  )#.to_list()
  zooniverse['subjects_id'] = [int(list(subject.keys())[0]) for subject in subjects]

  #retired status
  zooniverse["notretired"] = [subject[list(subject.keys())[0]]['retired'] is None for i,subject in enumerate(subjects)]

  retired = ~zooniverse["notretired"]

  #count annotations for each subject
  zooniverse['countannotation'] = zooniverse['subjects_id'].map(
    zooniverse['subjects_id'].value_counts())

  #subjects with multiple labels
  multilabel = zooniverse['countannotation'] > 1

  display(zooniverse.head())
  if verbose:
    print("missing values", zooniverse.isna().sum())
    print("label values", zooniverse["label"].unique())

  if savefile:
    fileout = "outputs/" + f"zooniversedf_saved_{date}.csv"
    zooniverse.to_csv(fileout)  
    print(f"file saved to {fileout}")
    
  return zooniverse, multilabel ,retired

if __name__ == "__main__":

  import argparse
  parser = argparse.ArgumentParser(
    formatter_class=argparse.ArgumentDefaultsHelpFormatter)

  parser.add_argument('filename', help='classfication file name')
  parser.add_argument('-v', '--verbose',
                      action='store_true', default=False, help='log level')
  parser.add_argument('--workflow_id', '--w', type=str, default="24125", help='workflow id (optional, default 24125)')
  parser.add_argument('--workflow_date', '--d', type=str, default="2025_11-10", help='workflow creation date (optional, default 2025_11-10)')
  #parser.print_help()
  
  args = parser.parse_args()

  infile = args.filename
  verbose = args.verbose
  workflow_id = args.workflow_id
  workdlow_creation_date =  args.workflow_date

  zooniverse, multilabel, retired = processclassifications(infile, workflow_id=workflow_id,
                                              workdlow_creation_date=workdlow_creation_date,
                                                           verbose=verbose, savefile=True)
  
  

