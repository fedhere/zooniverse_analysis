# -*- coding: utf-8 -*-
"""Zooniverse_analysis_FBB_02012026.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F31qiErgAra-4Bdd7sru_KMyb_H-IcMy
"""

###IMPORTANT!!!! CHECK FOR ######REMOVE!!!!!!! FOR SHORTCUTS THAT MUST BE REMOVED

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import LogNorm
import seaborn as sns
from tqdm import tqdm
from IPython.display import Image, display, HTML
import warnings
import json
import os
import time
from zooniverse_utils import *
from zooniverse_config import *
from o1_zooniverse_analysis_fbb_processclassifications import processclassifications


def get_core_team_labels(zooniverse, multilabel, mulitilabelsubjects,
                         coreteamnames, verbose=False, plotit=False):

  # zooniverse[multilabel] are all sublects w >1 labels
  ourlabels = zooniverse[zooniverse["user_name"].isin(ournames)].copy()
  if verbose:
    print("\n\n\n########### dataframe of core team labels with more than one label overall")
    display(ourlabels)

  if plotit:
    ourlabels.groupby("user_name").count()[["classification_id"]].plot.barh()
    plt.title("number of labels by core team member")
    ourlabels.groupby("subjects_id").count()[["classification_id"]].plot.barh()
    plt.title("number of objects by number of core team label")
    plt.yticks([])

  ourlabels['countannotation'] = ourlabels['subjects_id'].map(
    ourlabels['subjects_id'].value_counts())
  alllabels = ourlabels['countannotation'] > 0 #all out one core annotation
  our_rbdf, multilabelsubjects = createRBdf(ourlabels, alllabels, verbose=verbose, readsaved=True)
  
  our_rbdf["Real_fraction"] = our_rbdf["Real_count"] / (our_rbdf["Real_count"]+our_rbdf["Bogus_count"])
  our_rbdf["Bogus_fraction"] = our_rbdf["Bogus_count"] / (our_rbdf["Real_count"]+our_rbdf["Bogus_count"])
  if verbose:
      print(f"#### {our_rbdf.shape[0]} ground truth labels from core team")
  our_rbdf["total"] =  our_rbdf["Real_count"] + our_rbdf["Bogus_count"]
  our_rbdf["agreement"] = our_rbdf[['Real_fraction', 'Bogus_fraction']].max(axis=1)

  
  if verbose:
     print("\n\n\n########### the subjects that have more than one core team member labeled")
     display(ourlabels)

  

  ### create a dataframe with index the subjects and our annotations
  indices = np.unique(our_rbdf[our_rbdf["agreement"] >= AGREE_THR].index.to_list())
  print(f"#### {len(indices)} ground truth labels from core team with agreement threshold {AGREE_THR}")
  
  our_rbdf = pd.DataFrame(index=indices, columns = ["Real_count", "Bogus_count"])

  print("assembling core team labels dataframe")
  for ind in tqdm(indices):
      if ind in mulitilabelsubjects.index:
        #subjects with more tha one label
        our_rbdf.loc[ind, 'Bogus_count'] = mulitilabelsubjects.loc[ind].loc['Bogus',
                        'classification_id']  if 'Bogus' in mulitilabelsubjects.loc[ind].index else 0
        our_rbdf.loc[ind,'Real_count'] = mulitilabelsubjects.loc[ind].loc['Real',
                        'classification_id']  if 'Real' in mulitilabelsubjects.loc[ind].index else 0
      else:
        #subjects with only one label
        (our_rbdf.loc[ind, 'Bogus_count'], our_rbdf.loc[ind, 'Real_count']) = (1,0) \
        if ourlabels.loc[ourlabels["subject_ids"] == ind, "label"].values[0] == "Bogus" else (0,1)
  if verbose:
    display(our_rbdf)

  our_rbdf["Real_fraction"] = our_rbdf["Real_count"] / (our_rbdf["Real_count"]+our_rbdf["Bogus_count"])
  our_rbdf["Bogus_fraction"] = our_rbdf["Bogus_count"] / (our_rbdf["Real_count"]+our_rbdf["Bogus_count"])
  our_rbdf["total"] =  our_rbdf["Real_count"] + our_rbdf["Bogus_count"]
  our_rbdf["agreement"] = our_rbdf[['Real_fraction', 'Bogus_fraction']].max(axis=1)
  our_rbdf["ground_truth"] = ["Real" if r>0.5 else "Bogus" for r in our_rbdf["Real_fraction"]]

      
  if verbose:
    print(f"\n\n\n########### our labels DF: nlabels {our_rbdf.shape[0]}")
    display(our_rbdf.head(10))
  
  return our_rbdf

def get_gt_from_classifications(filein, workflow_id, verbose=False):
    ### then oxford labels ### ===> this is cumberson and should be rewritten!
    fromfilegt, _, _ = processclassifications(filein,
                                            workflow_id=30488, verbose=False)
  
    fromfilegt.replace("Bogus\n","Bogus", inplace=True) #just in case
    fromfilegt.replace("Real\n","Bogus", inplace=True) #just in case
    
    alllabels = [True]*len(fromfilegt)
    
    fromfilegt, multilabelsubjects = createRBdf(fromfilegt, alllabels, verbose=False, readsaved=False)

    if verbose:
      print(f"{fromfilegt.shape[0]} labels before cuts")
      
    #only use oxford data with more than one label
    fromfilegt["total"] = fromfilegt["Real_count"] + fromfilegt["Bogus_count"]
    fromfilegt = fromfilegt[fromfilegt["total"] > 1]
    
    if verbose:
      print(f"{fromfilegt.shape[0]} with more than one annotation")
    #only use oxford data with agreement above threshold

    fromfilegt["Real_fraction"] = fromfilegt["Real_count"] / (fromfilegt["Real_count"]+fromfilegt["Bogus_count"])
    fromfilegt["Bogus_fraction"] = fromfilegt["Bogus_count"] / (fromfilegt["Real_count"]+fromfilegt["Bogus_count"])
    fromfilegt["agreement"] = fromfilegt[['Real_fraction', 'Bogus_fraction']].max(axis=1)

    fromfilegt = fromfilegt[fromfilegt["agreement"] >= AGREE_THR]
    if verbose:
      print(f"{fromfilegt.shape[0]} above agreement threshold {AGREE_THR}")

    fromfilegt["ground_truth"] = ["Real" if r>0.5 else "Bogus" for r in fromfilegt["Real_fraction"]]
    return fromfilegt

                             
def create_groundtruth_training(rbdf, date, subjectsfile, verbose=False):
  rbdf_trainingdata = rbdf[rbdf["Real_count"] + rbdf["Bogus_count"] > 7]
  rbdf_trainingdata

  ### read subjects file #####
  chunks = []
  rbfile = f'rubin-difference-detectives-subjects_{date}.csv'
  if TEST:
    rbfile = rbfile.replace(".csv", "_short.csv")

  print(f"reading in file {rbfile}")
  
  for chunk in tqdm(pd.read_csv(rbfile, chunksize=chunk_size, low_memory=False)):
      # Process each chunk as needed
      chunks.append(chunk)
  subjects = pd.concat(chunks).drop_duplicates()

  # create the ground truth dataset: training data and labels created by core team
  training_ground_truth = {}
  print("assembling ground truth dataframe")
  for s in tqdm(rbdf_trainingdata.index):
    s = int(s)
    
    metadata_str = subjects[subjects["subject_id"] == s]["metadata"]
    if len(metadata_str) == 0:
      continue
   
    # Use json.loads() for strings instead of json.load()
    metadata_dict = json.loads(metadata_str.iloc[0])
    if not "#feedback_1_answer" in metadata_dict.keys():
      continue
    training_ground_truth[s] = "Real" if metadata_dict["#feedback_1_answer"] == "0" else "Bogus"
    if verbose:
      print(metadata_dict["#feedback_1_answer"], training_ground_truth[s])#0 == real 1 == bogus
  return subjects, training_ground_truth

def getground_truth(filein, date, read_ground_truth=False, verbose=False, plotit=False):
  zooniverse, multilabel, users = readinzooniverse(filein)
  ##### create rb dataframe ######
  rbdf, multilabelsubjects = createRBdf(zooniverse, multilabel, verbose=verbose, readsaved=False)

  ############get ground truths############

  subjectsfile = 'rubin-difference-detectives-subjects_{date}.csv'

  ### start with training data ###
  subjects, training_ground_truth = create_groundtruth_training(rbdf, date, subjectsfile, verbose=verbose)
  
  if verbose:
    print(training_ground_truth)

  coreteamnames = ["masao", "bellm", "acero",  "bianco", "brunosanchez"]
  our_rbdf = get_core_team_labels(zooniverse, multilabel, multilabelsubjects, coreteamnames,
                                  verbose=verbose, plotit=plotit)

  oxfordgt = get_gt_from_classifications("-atlas-eyeballers-rubin-difference-"
                                          "detectives-classifications.csv",
                                         workflow_id=30488, verbose=verbose)
  
  
  ### merge ground truth files ###
  
  full_ground_truth = pd.concat([our_rbdf[["ground_truth"]], pd.DataFrame.from_dict(training_ground_truth,
                                                                                    orient='index',
                                                                                    columns=['ground_truth']),
                                 oxfordgt[["ground_truth"]]])
  
  ### clean up and redesign the DF ###
  full_ground_truth = full_ground_truth.reset_index().rename({"index":"subject_id"}, axis=1)
  full_ground_truth["agreement"] = 0 # mock column
  full_ground_truth = full_ground_truth.groupby(["subject_id", "ground_truth"]).count()
  full_ground_truth = full_ground_truth['agreement'].unstack(level='ground_truth')
  full_ground_truth = full_ground_truth.rename(columns={'Bogus': 'Bogus_count', 'Real': 'Real_count'})
  full_ground_truth = full_ground_truth.fillna(0).astype(int)
  full_ground_truth["total"] = full_ground_truth["Bogus_count"] + full_ground_truth["Real_count"]
  full_ground_truth["agreement"] = full_ground_truth[['Bogus_count', 'Real_count']].max(axis=1) / full_ground_truth["total"]

  #only use if agreement above threshold
  full_ground_truth = full_ground_truth[full_ground_truth["agreement"] > AGREE_THR]
  full_ground_truth["ground_truth"] = full_ground_truth.apply(
    lambda row: 'Real' if row['Real_count'] > row['Bogus_count'] else 'Bogus',
    axis=1)
  
  if verbose:
    print("\n\n\n########### ground truth df")
    display(full_ground_truth.head(10))
    
    print("\n\n\n########### ground truth df aggregated by label count")
    display(full_ground_truth.groupby("total").count())
    
    print("\n\n\n########### ground truth df aggregated by classification agreement")
    display(full_ground_truth.groupby("agreement").count())

  if plotit:
    _ = full_ground_truth.groupby("agreement").count()[["ground_truth"]]
    _.index = [np.round(x, decimals=2) for x in _.index.values]
    _.plot.barh()
    #plt.yticks(plt.yticks()[0], [np.round(x, decimals=2) for x in plt.yticks()[0]])
    
    plt.ylabel("agreement")
    plt.xscale("log")
    plt.savefig(f"outputs/groun_truth_stats_agreement_{date}.png")
  
    full_ground_truth.groupby("total").count()[["ground_truth"]].plot.barh()
    plt.ylabel("total labels")
    plt.xscale("log")
    plt.savefig(f"outputs/ground_truth_stats_numbers_{date}.png")
    plt.show()
  
    print(f"#### save ground truth to outputs/full_ground_truth_{date}.csv")
    full_ground_truth.to_csv(f"outputs/full_ground_truth_{date}.csv")



if __name__ == "__main__":
  filein = f'outputs/zooniversedf_saved_{date}.csv'
  if TEST:
    filein = filein.replace(".csv", "_short.csv")
  getground_truth(filein, date, verbose=True, plotit=True)
